#!/usr/bin/perl -w
#!/usr/bin/perl -d:ptkdb
#
# $Id: run 1.48 Sun, 08 Apr 2007 23:19:01 -0500 hugo $
#

use strict;


our $core_directory;

our $built_exe_directory;

our $perl_modules_directory;

our $config;


BEGIN
{
    # default : running stand-alone

    my $test_mode = 'stand-alone';

    # find the package core directory

    $config = do 'tests.config';

    if (!defined $config)
    {
	if ($ENV{srcdir})
	{
	    $config = do "$ENV{srcdir}/tests.config";

	    # register that we are running from automake

	    $test_mode = 'automake';
	}
    }

    if (!defined $config)
    {
	die "No test configuration found";
    }

    # protect for automake

    if ($test_mode eq 'stand-alone')
    {
	$core_directory = $config->{core_directory};
    }
    else
    {
	$core_directory = "$ENV{srcdir}/$config->{core_directory}";

	#t breaks for distcheck: runs './../tests/run' in _build

# 	$core_directory = $config->{core_directory};

    }

    # remove parent and current directories

    $core_directory =~ s(([^\.])\./)($1)g;

    $core_directory =~ s([^/\.]+/\.\./)()g;

    print "$0: core_directory is $core_directory\n";

    # add to tests directory to include paths

    if (!exists $config->{tests_directory})
    {
	$config->{tests_directory} = "${core_directory}tests/specifications";
    }

    unshift @INC, $config->{tests_directory};

    # find the perl modules directory

    $perl_modules_directory = $core_directory;

    $perl_modules_directory .= "perl";

    # add to include path

    unshift @INC, $perl_modules_directory;

    # more automake hacking : if there is a special _build directory
    # that separates sources and derived files, we assume that the
    # _build directory will contain the executables.

    $built_exe_directory = $core_directory . "_build/";

    if (!-d $built_exe_directory)
    {
	$built_exe_directory = $core_directory;
    }
}


use Data::Comparator qw(data_comparator);
use Data::Transformator;

use Expect;

use Getopt::Long;

use YAML;


my $option_help;
my $option_regex_selector = ".*";
my $option_verbose;

# copy the model library

`mkdir /tmp/neurospaces`;

`rm -fr /tmp/neurospaces/test && mkdir /tmp/neurospaces/test && mkdir /tmp/neurospaces/test/models && cp -R ${core_directory}library/* /tmp/neurospaces/test/models`;

# automake distcheck makes the model library readonly (as so its copy), make it writable again

`chmod -R +w /tmp/neurospaces/test/models`;

# tell neurospaces where to find the model library of test models

$ENV{NEUROSPACES_MODELS} = "/tmp/neurospaces/test/models";


print "Executable is $0,\n";
print "core_directory is $core_directory\n";
print "Your models will be searched for in the directory $ENV{NEUROSPACES_MODELS}\n\n";


my $error_report = {};

my $error_count = 0;


$SIG{'INT'}
    = sub
      {
	  report_exit(2);
      };


sub main
{
    read_cmd_line();

    my $test_modules = test_library_construct();

    $test_modules = test_library_expand($test_modules);

    my $test_count = 0;

    # the initial error report is empty

    # compute the library checksum

    my $library_sha_before = model_library_sha();

    # loop over all test modules

    my $exp;

    my $running_command_definition;

    my $test_startup;

    foreach my $module_definition (@$test_modules)
    {
	if ($module_definition->{disabled})
	{
	    next;
	}

	my $module_name = $module_definition->{name};

	report_message(2, 1, "Running tests of module $module_definition->{description}");

	# loop over commands for this module

	my $command_definitions = $module_definition->{command_definitions};

	foreach my $command_definition (@$command_definitions)
	{
	    if ($command_definition->{disabled})
	    {
		next;
	    }

	    my $description = $command_definition->{description};

	    # give some diagnostics

	    if (@$command_definitions > 1)
	    {
		report_message(2, 1, "Running tests of $description");
	    }

	    my $preparation = $command_definition->{preparation};

	    my $preparation_result;

	    if ($preparation)
	    {
		print "*** Preparing ($preparation->{description})\n";

		my $preparer = $preparation->{preparer};

		$preparation_result = &$preparer();
	    }

	    my $command = $command_definition->{command};

	    if (ref $command eq 'CODE')
	    {
	    }
	    else
	    {
		# a command can come from the _build directory
		# or from the sources for a script

		my $test_command
		    = -f $built_exe_directory . $command
			? $built_exe_directory . $command
			    : $core_directory . $command;

		# if there are differences between how to run this
		# command and the one already running

		my $new_command_definition
		    = {
		       arguments => $command_definition->{arguments},
		       command => $test_command,
		      };

		my $differences
		    = data_comparator
			($new_command_definition, $running_command_definition);

		my $spawn_new = !$exp || !$differences->is_empty();

		# prefix the command with the core directory

		$command = $new_command_definition->{command};

		my $arguments = $command_definition->{arguments};

		if ($spawn_new)
		{
		    if ($exp)
		    {
			# terminate the previous command

			#t could be that the hard_close() call is needed because
			#t neurospaces uses readline, not sure needs investigation,
			#t perhaps.

			$exp->hard_close();
		    }

		    # create a new Expect object by spawning a new process with the new command

		    $exp = Expect->new();

		    #! see the expect manual for this one

		    $exp->raw_pty(1);

# 		    $exp->slave->stty(qw(raw -echo));

		    $exp->spawn($command, @$arguments)
			or die "$0: cannot spawn $command: $!\n";

		    # set the running_command_definition

		    $running_command_definition = $new_command_definition;

		    print "*** Executing $command " . (join ' ', map { "'$_'" } @$arguments) . "\n";

		    $test_startup = 1;
		}
		else
		{
		    print "*** Recycling $command " . (join ' ', map { "'$_'" } @$arguments) . "\n";

		    $test_startup = 0;
		}
	    }

	    # loop over all tests for this module

	    my $command_tests = $command_definition->{command_tests};

	    foreach my $command_test (@$command_tests)
	    {
		if ($command_test->{disabled})
		{
		    next;
		}

		# expect this output

		my ($matched_pattern_position,
		    $error,
		    $successfully_matching_string,
		    $before_match,
		    $after_match);

		if (ref $command eq 'CODE')
		{
		    $error
			= &$command
			    (
			     $command_test,
			     {
			      c_code => {
					 directory => $core_directory,
					},
			     },
			    );
		}
		else
		{
		    # give feedback about this specific test

		    my $description = $command_test->{description};

		    print "*** Test : $description\n";

		    if ($description =~ /startup successful \?$/)
		    {
			if (!$test_startup)
			{
			    print "*** Skipped : not testing startup tests on a recycled command ($description)\n";

			    next;
			}
		    }

		    # set read and write strings

		    my $read = $command_test->{read};

		    my $write = $command_test->{write};

		    # set timeout, defaults to one second

		    my $timeout = defined $command_test->{timeout} ? $command_test->{timeout} : 2;

		    # write

		    if (defined $write)
		    {
			$exp->send("$write\n");
		    }

		    # read

		    if (defined $read)
		    {
			# substitute variables

			$read = substitute_variables($read);

			if (!ref $read)
			{
			    ($matched_pattern_position,
			     $error,
			     $successfully_matching_string,
			     $before_match,
			     $after_match)
				= $exp->expect($timeout, $read, );
			}

			#! only array supported for now.

			else
			{
			    ($matched_pattern_position,
			     $error,
			     $successfully_matching_string,
			     $before_match,
			     $after_match)
				= $exp->expect($timeout, @$read, );
			}
		    }
		}

		# process errors

		if ($error)
		{
		    my $description = $command_test->{description};

		    my $command_definition_description = $command_definition->{description};

# 		    $error_count++;

# 		    print STDERR "*** Error: $error ($description)\n";

# 		    # fill in the error report

# 		    $error_report->{global}->{error_count} = $error_count;

# 		    $error_report->{modules}->{$module_name}->{$error_count}->{$command_definition_description}->{description} = $command_test->{description};
# 		    $error_report->{modules}->{$module_name}->{$error_count}->{error} = $error;

# 		    if ($option_verbose)
# 		    {
# 			$error_report->{modules}->{$module_name}->{$error_count}->{$command_definition_description}->{report}
# 			    = $before_match;
# 		    }

		    my $message;

		    if ($option_verbose)
		    {
			$message = $before_match;
		    }

 		    report_error_add($module_name, $description, $command_definition_description, $error, $message);

		}

		my $reparation = $command_definition->{reparation};

		if ($reparation)
		{
		    print "*** Reparing ($reparation->{description})\n";

		    my $reparer = $reparation->{reparer};

		    my $reparation_error = &$reparer($preparation_result);

		    # process errors

		    if ($reparation_error)
		    {
			my $description = $reparation_error;

			my $command_definition_description = $command_definition->{description};

# 			$error_count++;

# 			print STDERR "*** Error: $reparation_error ($description)\n";

# 			# fill in the error report

# 			$error_report->{global}->{error_count} = $error_count;

# 			$error_report->{modules}->{$module_name}->{$error_count}->{$command_definition_description}->{description} = $command_test->{description};
# 			$error_report->{modules}->{$module_name}->{$error_count}->{error} = $reparation_error;

			report_error_add($module_name, $description, $command_definition_description, $reparation_error);
		    }
		}

		$test_count++;
	    }

	    if (@$command_definitions > 1)
	    {
		report_message(1, 2, "End for tests of $description
Total of $test_count tests (encountered $error_count error(s) so far)");
	    }
	}

	# if library checksum mismatch

	my $library_sha_after = model_library_sha();

	if ($library_sha_after ne $library_sha_before)
	{
	    my $error = 'model library checksum mismatch (model library has changed)';

	    my $description = $module_definition->{description};

# 	    $error_count++;

# 	    print STDERR "*** Error: $error ($description)\n";

# 	    # fill in the error report

# 	    $error_report->{global}->{error_count} = $error_count;

# 	    $error_report->{modules}->{$module_name}->{$error_count}->{description} = $module_definition->{description};
# 	    $error_report->{modules}->{$module_name}->{$error_count}->{error} = $error;

	    report_error_add($module_name, $description, undef, $error);
	}

	report_message(1, 2, "End of tests of module $module_definition->{description}
Total of $test_count tests (encountered $error_count error(s) so far)");
    }

    # if there is a command running

    if ($exp)
    {
	# terminate the command

	#t could be that the hard_close() call is needed because
	#t neurospaces uses readline, not sure needs investigation,
	#t perhaps.

	$exp->hard_close();
    }

    report_exit(0);
}


sub read_cmd_line
{
    my $result
	= GetOptions
	    (
	     "help!" => \$option_help,
	     "regex-selector=s" => \$option_regex_selector,
	     "v|verbose+" => \$option_verbose,
	    );

    if ($option_help)
    {
	print
	    "
$0: test definition executor

options :
    regex-selector  defines a regex to run specific tests.
    help            print usage information.
    verbose         set verbosity level.
";

	exit 1;
    }

}


sub report_error_add
{
    my $module = shift;

    my $description = shift;

    my $subdescription = shift;

    my $error = shift;

    my $message = shift;

    $error_count++;

    print STDERR "*** Error: $error ($description, $module)\n";

    # fill in the error report

    $error_report->{global}->{error_count} = $error_count;

    if ($subdescription)
    {
	$error_report->{modules}->{$module}->{$error_count}->{$subdescription}->{description} = $description;
    }
    else
    {
	$error_report->{modules}->{$module}->{$error_count}->{description} = $description;
    }

    $error_report->{modules}->{$module}->{$error_count}->{error} = $error;

    if (defined $message)
    {
	$error_report->{modules}->{$module}->{$error_count}->{$subdescription}->{report} = $message;
    }
}


sub report_exit
{
    my $exit_code = shift;

    # if there were errors

    if ($error_count)
    {
	# yaml out the error report

	print Dump($error_report);

	# exit with failure

	$exit_code ||= 1;

	print "$0: exit_code $exit_code\n";

	exit $exit_code;
    }

    # else

    else
    {
	# exit, possibly success

	exit $exit_code;
    }
}


sub report_message
{
    my $header = shift;

    my $trailer = shift;

    my $message = shift;

    my $lines = [ split '\n', $message, ];

    my $longest = 0;

    map
    {
	($longest < length) && ($longest = length)
    }
	@$lines;

    my $line = '-' x $longest;

    print "\n";
    print "$line\n" for 0 .. $header;
    print "\n";
    print "$message\n\n";
    print "$line\n" for 0 .. $trailer;
    print "\n";
}


sub substitute_variables
{
    my $string = shift;

    my $variables
	= [
	   [ '$(libdir)' => "$core_directory/tests/models", ],
	  ];

    foreach my $variable (@$variables)
    {
	my $searcher = quotemeta($variable->[0]);

	$string =~ s/$searcher/$variable->[1]/g;
    }

    return $string;
}


sub test_library_construct
{
    # define the tests

    my $additional_test_modules
	= [
	  ];

    my $program_name = $0;

    $program_name =~ s/.*\///;

    my $library = $0;

    $library =~ s/$program_name$/specifications/;

    my $test_modules
	= [
	   @$additional_test_modules,
	   map
	   {
	       chomp; $_;
	   }
	   `find $config->{tests_directory} -name "*.t"`,
	  ];

    return $test_modules;
}


sub test_library_expand
{
    my $library = shift;

    my $result = [];

    # parse all modules

    foreach my $test_module (@$library)
    {
	if ($test_module !~ /$option_regex_selector/i)
	{
	    next;
	}

	my $module_definition = do $test_module;

	if ($@)
	{
	    report_error_add($test_module, $@, undef, $@);
	}
	else
	{
	    if (!$module_definition->{disabled})
	    {
		push @$result, $module_definition;
	    }
	}
    }

    # sort modules

    #t first need to transform: select command_definitions, flatten
    #t out, keep the module names (for referencing errors).

    my $transformator
	= Data::Transformator->new
	    (
             apply_identity_transformation => 0,
	     name => 'test-module-selector',
	     contents => $result,
	     separator => '`',
	     array_filter =>
	     sub
	     {
		 my ($context, $component) = @_;

		 # never filter for the first two component in the path

		 my $depth = $context->{array};
		 $depth = $#$depth;

		 if ($depth < 2)
		 {
		     return 1;
		 }

		 # extract the data

		 $context->{path} =~ m|^[^/]*/([^/]*)/([^/]*)|;

		 my $content = Data::Transformator::_context_get_current_content($context);

		 # push it onto the result

		 my $result = Data::Transformator::_context_get_main_result($context);

		 if (!$result->{content})
		 {
		     $result->{content} = [];
		 }

		 push @{$result->{content}}, $content;

		 # add the module name

		 my $module_name = $context->{array}->[1]->{content}->{name};

		 $content->{module_name} = $module_name;

		 # result is known, everything gets filtered

		 0;
	     },
	    );

    #t for an empty array as content, the transformator returns an
    #t undef, this is a bug that still needs fixing.

    my $tests = $transformator->transform() || [];

    $tests
	= [
	   sort
	   {
	       my $module1 = $a;
	       my $module2 = $b;

# 	       my $command1 = $module1->{command_definitions}->[0]->{command};
# 	       my $command2 = $module2->{command_definitions}->[0]->{command};

# 	       my $command1_arguments = $module1->{command_definitions}->[0]->{arguments};
# 	       my $command2_arguments = $module2->{command_definitions}->[0]->{arguments};

	       my $command1 = $module1->{command};
	       my $command2 = $module2->{command};

	       my $command1_arguments = $module1->{arguments} || [];
	       my $command2_arguments = $module2->{arguments} || [];

	       my $command1_string = join ' ', $command1, @$command1_arguments;
	       my $command2_string = join ' ', $command2, @$command2_arguments;

	       my $comparison = $command1_string cmp $command2_string;

	       if ($module1->{tester_head})
	       {
		   $comparison = -1;
	       }
	       elsif ($module2->{tester_head})
	       {
		   $comparison = 1;
	       }

	       $comparison;
	   }
	   @$tests,
	  ];

    #t Need to figure out how to deal with the library reparation and
    #t preparation.

    # return result

    return $result;
}


sub model_library_sha
{
    # find all models

    use File::Find::Rule;

    my $files = [ File::Find::Rule->file()->in( $ENV{NEUROSPACES_MODELS} ), ];

    my $shas
	= [
	   map
	   {
	       `sha1sum $_`;
	   }
	   @$files,
	  ];

    use Digest::SHA qw(sha1_hex);

    my $sha = sha1_hex(join ', ', @$shas);

    return $sha;
}


main();


